{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Keyword spotting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first import all the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import sys\n",
        "<\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check if CUDA is available and if it's the case then all our calculus will be way faster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.], device='cuda:0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(1).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A data point in the SPEECHCOMMANDS dataset is a tuple made of a waveform\n",
        "(the audio signal), the sample rate, the utterance (label), the ID of\n",
        "the speaker, the number of the utterance.\n",
        "\n",
        "We can visualize the first one of the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we can list of labels available in the dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['down',\n",
              " 'left',\n",
              " 'off',\n",
              " 'on',\n",
              " 'right',\n",
              " 'silence',\n",
              " 'stop',\n",
              " 'unknown',\n",
              " 'up',\n",
              " 'yes']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
        "labels = ['down',\n",
        "            'left',\n",
        "            'off',\n",
        "            'on',\n",
        "            'right',\n",
        "            'silence',\n",
        "            'stop',\n",
        "            'unknown',\n",
        "            'up',\n",
        "            'yes']\n",
        "labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are encoding each word using its index in the list of labels.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unknown --> tensor(7) --> unknown\n"
          ]
        }
      ],
      "source": [
        "def label_to_index(word):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "\n",
        "def index_to_label(index):\n",
        "    # Return the word corresponding to the index in labels\n",
        "    # This is the inverse of label_to_index\n",
        "    return labels[index]\n",
        "\n",
        "\n",
        "word_start = \"unknown\"\n",
        "index = label_to_index(word_start)\n",
        "word_recovered = index_to_label(index)\n",
        "\n",
        "print(word_start, \"-->\", index, \"-->\", word_recovered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To turn a list of data point made of audio recordings and utterances\n",
        "into two batched tensors for the model, we implement a collate function\n",
        "which is used by the PyTorch DataLoader that allows us to iterate over a\n",
        "dataset by batches. Please see [the\n",
        "documentation](https://pytorch.org/docs/stable/data.html#working-with-collate-fn)_\n",
        "for more information about working with a collate function.\n",
        "\n",
        "In the collate function, we also apply the resampling, and the text\n",
        "encoding.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a training function, we need to make one for testing\n",
        "the networks accuracy. We will set the model to ``eval()`` mode and then\n",
        "run inference on the test dataset. Calling ``eval()`` sets the training\n",
        "variable in all modules in the network to false. Certain layers like\n",
        "batch normalization and dropout layers behave differently during\n",
        "training so this step is crucial for getting correct results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here we load the model (trained with the same technique in another notebook) :\n",
        "Here, a CNN model trained with 21 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded and ready for inference.\n",
            "M5(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Number of parameters: 66026\n"
          ]
        }
      ],
      "source": [
        "import torchaudio.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(n_input, n_channel, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.bn1 = nn.BatchNorm2d(n_channel)\n",
        "        self.pool1 = nn.MaxPool2d((2, 2))\n",
        "        self.conv2 = nn.Conv2d(n_channel, n_channel, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.bn2 = nn.BatchNorm2d(n_channel)\n",
        "        self.pool2 = nn.MaxPool2d((2, 2))\n",
        "        self.conv3 = nn.Conv2d(n_channel, 2 * n_channel, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.bn3 = nn.BatchNorm2d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool2d((2, 2))\n",
        "        self.conv4 = nn.Conv2d(2 * n_channel, 2 * n_channel, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.bn4 = nn.BatchNorm2d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool2d((2, 2))\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f\"Input shape: {x.shape}\")\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        # print(f\"Shape after conv1: {x.shape}\")\n",
        "        x = self.pool1(x)\n",
        "        # print(f\"Shape after pool1: {x.shape}\")\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        # print(f\"Shape after conv2: {x.shape}\")\n",
        "        x = self.pool2(x)\n",
        "        # print(f\"Shape after pool2: {x.shape}\")\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        # print(f\"Shape after conv3: {x.shape}\")\n",
        "        x = self.pool3(x)\n",
        "        # print(f\"Shape after pool3: {x.shape}\")\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        # print(f\"Shape after conv4: {x.shape}\")\n",
        "        x = self.pool4(x)\n",
        "        # print(f\"Shape after pool4: {x.shape}\")\n",
        "        x = F.adaptive_avg_pool2d(x, 1).squeeze()\n",
        "        # print(f\"Shape after adaptive_avg_pool2d: {x.shape}\")\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        x = self.fc1(x)\n",
        "        # print(f\"Shape before log_softmax: {x.shape}\")\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "n_input = 1  # Adjust according to your input data shape\n",
        "n_output = len(labels) # Adjust according to the number of output classes\n",
        "model = M5(n_input=n_input, n_output=n_output)\n",
        "# model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load('modelMFCCNoisySilenceSet90.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# If you are using a GPU, move the model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded and ready for inference.\")\n",
        "\n",
        "print(model)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    return tensor.argmax(dim=-1)\n",
        "\n",
        "\n",
        "def pad_or_trim(tensor, target_length):\n",
        "    if tensor.size(-1) > target_length:\n",
        "        return tensor[:, :target_length]\n",
        "    elif tensor.size(-1) < target_length:\n",
        "        return F.pad(tensor, (0, target_length - tensor.size(-1)))\n",
        "    return tensor\n",
        "\n",
        "\n",
        "\n",
        "class CustomMFCCTransform(nn.Module):\n",
        "    def __init__(self, sample_rate, n_mfcc, n_fft, n_mels, hop_length):\n",
        "        super().__init__()\n",
        "        self.mfcc_transform = torchaudio.transforms.MFCC(\n",
        "            sample_rate=sample_rate,\n",
        "            n_mfcc=n_mfcc,\n",
        "            melkwargs={\n",
        "                \"n_fft\": n_fft,\n",
        "                \"n_mels\": n_mels,\n",
        "                \"hop_length\": hop_length,\n",
        "                \"mel_scale\": \"htk\",\n",
        "            },\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device  # Get the device of the input tensor\n",
        "        self.mfcc_transform.to(device)\n",
        "        x = self.mfcc_transform(x)  # Apply MFCC\n",
        "        return x\n",
        "\n",
        "n_fft = 2048\n",
        "win_length = None\n",
        "hop_length = 512\n",
        "n_mels = 256\n",
        "n_mfcc = 256\n",
        "sample_rate = 16000\n",
        "\n",
        "# Define the custom MFCC transformation\n",
        "transform = CustomMFCCTransform(\n",
        "    sample_rate=sample_rate,\n",
        "    n_mfcc=n_mfcc,\n",
        "    n_fft=n_fft,\n",
        "    n_mels=n_mels,\n",
        "    hop_length=hop_length\n",
        ")\n",
        "\n",
        "\n",
        "def predict(tensor):\n",
        "    target_length = 16000  # Assurez-vous que toutes les entrées ont une longueur cohérente\n",
        "    tensor = pad_or_trim(tensor, target_length)\n",
        "    # print(f\"Original tensor shape: {tensor.shape}\")\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = transform(tensor)\n",
        "    # print(f\"Shape after transform: {tensor.shape}\")\n",
        "    tensor = model(tensor.unsqueeze(0))\n",
        "    tensor = get_likely_index(tensor)\n",
        "    tensor = index_to_label(tensor.squeeze())\n",
        "    return tensor\n",
        "\n",
        "\n",
        "# waveform, sample_rate, utterance, *_ = train_set[-1]\n",
        "# ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "\n",
        "# print(f\"Expected: {utterance}. Predicted: {predict(waveform)}.\")\n",
        "\n",
        "# waveform, sample_rate, utterance, *_ = test_set[931]\n",
        "# ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "# print(f\"data {40} : Expected: {utterance}. Predicted: {predict(waveform)}.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Listening ...]\n",
            "Data point #1 predicted: up.\n",
            "Data point #2 predicted: silence.\n",
            "Data point #3 predicted: silence.\n",
            "Data point #4 predicted: silence.\n",
            "Data point #5 predicted: silence.\n",
            "Stopping ...\n",
            "Recorder deleted.\n"
          ]
        }
      ],
      "source": [
        "from pvrecorder import PvRecorder\n",
        "import numpy as np \n",
        "\n",
        "def preprocess_audio(audio_data, sample_rate=16000):\n",
        "    # Convertir en tensor\n",
        "    waveform = torch.tensor(audio_data, dtype=torch.float32)\n",
        "    waveform = waveform / 32768.0  # Normaliser\n",
        "    return waveform\n",
        "\n",
        "\n",
        "recorder = None\n",
        "i = 0\n",
        "frame_length = 16000 // 1  # Taille du pas (0.1 seconde à une fréquence d'échantillonnage de 16000 Hz)\n",
        "window_size = 16000  # Taille de la fenêtre (1 seconde à une fréquence d'échantillonnage de 16000 Hz)\n",
        "\n",
        "audio_buffer = np.zeros(window_size, dtype=np.int16)\n",
        "\n",
        "try:\n",
        "    recorder = PvRecorder(frame_length=frame_length, device_index=1)\n",
        "    recorder.start()\n",
        "    print('[Listening ...]')\n",
        "\n",
        "    while True:\n",
        "        i += 1\n",
        "        pcm = recorder.read()\n",
        "        audio_buffer = np.roll(audio_buffer, -frame_length)\n",
        "        audio_buffer[-frame_length:] = pcm\n",
        "        pcm2 = preprocess_audio(audio_buffer.tolist())\n",
        "\n",
        "        if pcm2.dim() == 1:\n",
        "            pcm2 = pcm2.unsqueeze(0)\n",
        "\n",
        "        output = predict(pcm2)\n",
        "        print(f\"Data point #{i} predicted: {output}.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    sys.stdout.write('\\b' * 2)\n",
        "    print('Stopping ...')\n",
        "\n",
        "finally:\n",
        "    if recorder is not None:\n",
        "        recorder.delete()\n",
        "        print('Recorder deleted.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Listening ...]\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "left\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "up\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "silence\n",
            "Stopping ...\n",
            "Recorder deleted.\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "import time\n",
        "import random\n",
        "\n",
        "pygame.init()\n",
        "\n",
        "white = (255, 255, 255)\n",
        "yellow = (255, 255, 102)\n",
        "black = (0, 0, 0)\n",
        "red = (213, 50, 80)\n",
        "green = (0, 255, 0)\n",
        "blue = (50, 153, 213)\n",
        "\n",
        "dis_width = 800\n",
        "dis_height = 600\n",
        "\n",
        "dis = pygame.display.set_mode((dis_width, dis_height))\n",
        "pygame.display.set_caption('Snake Game with Voice Commands')\n",
        "\n",
        "clock = pygame.time.Clock()\n",
        "snake_block = 10\n",
        "snake_speed = 15\n",
        "\n",
        "font_style = pygame.font.SysFont(\"bahnschrift\", 25)\n",
        "score_font = pygame.font.SysFont(\"comicsansms\", 35)\n",
        "\n",
        "def our_snake(snake_block, snake_list):\n",
        "    for x in snake_list:\n",
        "        pygame.draw.rect(dis, black, [x[0], x[1], snake_block, snake_block])\n",
        "\n",
        "def message(msg, color):\n",
        "    mesg = font_style.render(msg, True, color)\n",
        "    dis.blit(mesg, [dis_width / 6, dis_height / 3])\n",
        "\n",
        "def gameLoop():\n",
        "    global audio_buffer, recorder, frame_length, window_size\n",
        "\n",
        "    game_over = False\n",
        "    game_close = False\n",
        "\n",
        "    x1 = dis_width / 2\n",
        "    y1 = dis_height / 2\n",
        "\n",
        "    x1_change = 0\n",
        "    y1_change = 0\n",
        "\n",
        "    snake_List = []\n",
        "    Length_of_snake = 1\n",
        "\n",
        "    foodx = round(random.randrange(0, dis_width - snake_block) / 10.0) * 10.0\n",
        "    foody = round(random.randrange(0, dis_height - snake_block) / 10.0) * 10.0\n",
        "\n",
        "    frame_length = 16000 // 1\n",
        "    window_size = 16000\n",
        "    audio_buffer = np.zeros(window_size, dtype=np.int16)\n",
        "\n",
        "    recorder = PvRecorder(frame_length=frame_length, device_index=0)\n",
        "    recorder.start()\n",
        "    print('[Listening ...]')\n",
        "\n",
        "    try:\n",
        "        while not game_over:\n",
        "\n",
        "            while game_close:\n",
        "                dis.fill(blue)\n",
        "                message(\"You Lost! Press Q-Quit or C-Play Again\", red)\n",
        "                pygame.display.update()\n",
        "\n",
        "                for event in pygame.event.get():\n",
        "                    if event.type == pygame.KEYDOWN:\n",
        "                        if event.key == pygame.K_q:\n",
        "                            game_over = True\n",
        "                            game_close = False\n",
        "                        if event.key == pygame.K_c:\n",
        "                            gameLoop()\n",
        "                            return\n",
        "\n",
        "            for event in pygame.event.get():\n",
        "                if event.type == pygame.QUIT:\n",
        "                    game_over = True\n",
        "                if event.type == pygame.KEYDOWN:\n",
        "                    if event.key == pygame.K_LEFT and x1_change == 0:\n",
        "                        x1_change = -snake_block\n",
        "                        y1_change = 0\n",
        "                    elif event.key == pygame.K_RIGHT and x1_change == 0:\n",
        "                        x1_change = snake_block\n",
        "                        y1_change = 0\n",
        "                    elif event.key == pygame.K_UP and y1_change == 0:\n",
        "                        y1_change = -snake_block\n",
        "                        x1_change = 0\n",
        "                    elif event.key == pygame.K_DOWN and y1_change == 0:\n",
        "                        y1_change = snake_block\n",
        "                        x1_change = 0\n",
        "\n",
        "            pcm = recorder.read()\n",
        "            audio_buffer = np.roll(audio_buffer, -frame_length)\n",
        "            audio_buffer[-frame_length:] = pcm\n",
        "            pcm2 = preprocess_audio(audio_buffer.tolist())\n",
        "\n",
        "            if pcm2.dim() == 1:\n",
        "                pcm2 = pcm2.unsqueeze(0)\n",
        "\n",
        "            output = predict(pcm2)\n",
        "            print(output)\n",
        "\n",
        "            if output == 'left' and x1_change == 0:\n",
        "                x1_change = -snake_block\n",
        "                y1_change = 0\n",
        "            elif output == 'right' and x1_change == 0:\n",
        "                x1_change = snake_block\n",
        "                y1_change = 0\n",
        "            elif output == 'up' and y1_change == 0:\n",
        "                y1_change = -snake_block\n",
        "                x1_change = 0\n",
        "            elif output == 'down' and y1_change == 0:\n",
        "                y1_change = snake_block\n",
        "                x1_change = 0\n",
        "\n",
        "            if x1 >= dis_width or x1 < 0 or y1 >= dis_height or y1 < 0:\n",
        "                game_close = True\n",
        "            x1 += x1_change\n",
        "            y1 += y1_change\n",
        "            dis.fill(blue)\n",
        "            pygame.draw.rect(dis, green, [foodx, foody, snake_block, snake_block])\n",
        "            snake_Head = []\n",
        "            snake_Head.append(x1)\n",
        "            snake_Head.append(y1)\n",
        "            snake_List.append(snake_Head)\n",
        "            if len(snake_List) > Length_of_snake:\n",
        "                del snake_List[0]\n",
        "\n",
        "            for x in snake_List[:-1]:\n",
        "                if x == snake_Head:\n",
        "                    game_close = True\n",
        "\n",
        "            our_snake(snake_block, snake_List)\n",
        "\n",
        "            pygame.display.update()\n",
        "\n",
        "            if x1 == foodx and y1 == foody:\n",
        "                foodx = round(random.randrange(0, dis_width - snake_block) / 10.0) * 10.0\n",
        "                foody = round(random.randrange(0, dis_height - snake_block) / 10.0) * 10.0\n",
        "                Length_of_snake += 1\n",
        "\n",
        "            clock.tick(snake_speed)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        sys.stdout.write('\\b' * 2)\n",
        "        print('Stopping ...')\n",
        "\n",
        "    finally:\n",
        "        if recorder is not None:\n",
        "            recorder.delete()\n",
        "            print('Recorder deleted.')\n",
        "\n",
        "    pygame.quit()\n",
        "\n",
        "gameLoop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
